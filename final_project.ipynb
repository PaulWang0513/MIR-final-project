{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Importing Packages =====\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of audio files: 65\n",
      "===== Preprocess Data =====\n",
      "Processing 最長的電影01.wav ...\n",
      "Processing 最長的電影02.wav ...\n",
      "Processing 最長的電影03.wav ...\n",
      "Processing 最長的電影04.wav ...\n",
      "Processing 最長的電影05.wav ...\n",
      "Processing 最長的電影06.wav ...\n",
      "Processing 最長的電影07.wav ...\n",
      "Processing 最長的電影08.wav ...\n",
      "Processing 最長的電影09.wav ...\n",
      "Processing 最長的電影10.wav ...\n",
      "Processing 最長的電影11.wav ...\n",
      "Processing 最長的電影12.wav ...\n",
      "Processing 蒲公英的約定01.wav ...\n",
      "Processing 蒲公英的約定02.wav ...\n",
      "Processing 蒲公英的約定03.wav ...\n",
      "Processing 蒲公英的約定04.wav ...\n",
      "Processing 蒲公英的約定05.wav ...\n",
      "Processing 蒲公英的約定06.wav ...\n",
      "Processing 蒲公英的約定07.wav ...\n",
      "Processing 蒲公英的約定08.wav ...\n",
      "Processing 蒲公英的約定09.wav ...\n",
      "Processing 蒲公英的約定10.wav ...\n",
      "Processing 蒲公英的約定11.wav ...\n",
      "Processing 蒲公英的約定12.wav ...\n",
      "Processing 蒲公英的約定13.wav ...\n",
      "Processing 蒲公英的約定14.wav ...\n",
      "Processing 蒲公英的約定15.wav ...\n",
      "Processing 最長的電影13.wav ...\n",
      "Processing 最長的電影14.wav ...\n",
      "Processing 最長的電影15.wav ...\n",
      "Processing 最長的電影16.wav ...\n",
      "Processing 最長的電影17.wav ...\n",
      "Processing 最長的電影18.wav ...\n",
      "Processing 彩虹01.wav ...\n",
      "Processing 彩虹02.wav ...\n",
      "Processing 彩虹03.wav ...\n",
      "Processing 彩虹04.wav ...\n",
      "Processing 彩虹05.wav ...\n",
      "Processing 彩虹06.wav ...\n",
      "Processing 彩虹07.wav ...\n",
      "Processing 彩虹08.wav ...\n",
      "Processing 彩虹09.wav ...\n",
      "Processing 青花瓷01.wav ...\n",
      "Processing 青花瓷02.wav ...\n",
      "Processing 青花瓷03.wav ...\n",
      "Processing 青花瓷04.wav ...\n",
      "Processing 青花瓷05.wav ...\n",
      "Processing 青花瓷06.wav ...\n",
      "Processing 青花瓷07.wav ...\n",
      "Processing 青花瓷08.wav ...\n",
      "Processing 青花瓷09.wav ...\n",
      "Processing 牛仔很忙01.wav ...\n",
      "Processing 牛仔很忙02.wav ...\n",
      "Processing 牛仔很忙03.wav ...\n",
      "Processing 牛仔很忙04.wav ...\n",
      "Processing 牛仔很忙05.wav ...\n",
      "Processing 牛仔很忙06.wav ...\n",
      "Processing 牛仔很忙07.wav ...\n",
      "Processing 牛仔很忙08.wav ...\n",
      "Processing 牛仔很忙09.wav ...\n",
      "Processing 牛仔很忙10.wav ...\n",
      "Processing 牛仔很忙11.wav ...\n",
      "Processing 牛仔很忙12.wav ...\n",
      "Processing 牛仔很忙13.wav ...\n",
      "Processing 牛仔很忙14.wav ...\n",
      "Done!\n",
      "===== Prepare Dataset =====\n",
      "mfcc_array: (30074, 440)\n",
      "label_array: (30074,)\n",
      "X_train: (24059, 440)\n",
      "y_train: (24059,)\n",
      "X_test: (6015, 440)\n",
      "y_test: (6015,)\n",
      "number of classes: 368\n",
      "['no lyrics' '一個' '一如' '一種' '一笑' '一縷飄散' '一起' '一起上' '三年' '上帝' '不喝' '不壓'\n",
      " '不是' '不用麻煩' '不用麻煩了' '不長' '不開口' '也是' '也累了' '也能' '也許' '也還是' '了然' '介紹' '仕女圖'\n",
      " '任性' '伏筆' '但' '你們' '依賴' '信' '假牛皮' '傳來' '先來杯' '兩分鐘' '冉冉' '再給' '再重來' '冰'\n",
      " '冰上的' '冰刀' '分不清' '初妝' '別沒收' '別融化了' '到底能' '前朝的' '剪影' '副歌' '劃的' '勾勒出' '千年的'\n",
      " '千萬里' '午睡' '卻' '卻不知道' '去' '去不了的' '去到' '友情' '口琴' '口罩' '只' '叫' '含苞待放' '吹著'\n",
      " '告訴' '呼喚' '命運的' '哪裡' '哭' '唯一' '啤酒' '善良的' '喔跌倒時' '嗚啦啦啦' '囂張' '因為' '圈'\n",
      " '圈起了' '在' '在乎' '在等待著' '在走廊上' '地方' '地球' '堅持的' '墨色' '夕陽下' '多少年後' '多遠' '夢'\n",
      " '天' '天青色' '太多' '太陽' '奔騰的' '奶昔' '好了' '如今' '如傳世的' '如果' '妝' '妳' '妳的' '嫣然的'\n",
      " '子彈' '它沒長' '安靜' '宋體' '完了' '宣紙上' '寄成' '寫' '將' '小妹妹' '小學' '小毛驢' '就' '就當'\n",
      " '就算' '就縮成' '山水畫裡' '已經' '彩虹' '很多人' '很多的' '很好聽' '很忙的' '很簡單' '很緊' '從' '心'\n",
      " '心事' '忘了吧' '忘記' '怎麼' '惦記著' '惹了' '愛' '愛情' '慢慢' '成真不了' '我' '我們' '我們的'\n",
      " '我啦啦啦' '我的' '我票' '我那隻' '所有的' '手心' '才' '才明白' '才珍貴' '打' '打過勾的' '把' '投' '折'\n",
      " '抱不到' '接下來' '描繪的' '換介紹' '操場' '擱一半' '改變' '放映了' '放開' '旅行' '旋轉' '日記' '昇起'\n",
      " '明白' '是' '是一種' '是不是' '是個' '是很長的' '時間' '暈開了' '書' '曾經' '最後' '會' '會不會' '月色'\n",
      " '有味道的' '有幾個' '有沒有' '有顆' '望著' '朦朧的' '極細膩' '槍口' '橡皮筋' '檀香' '正服下的' '正義' '武器'\n",
      " '每天' '毒藥' '決定' '決鬥' '沒有' '泡泡浴' '注意' '洗澡' '淡' '深處' '清晰' '渲染' '溜了' '漢隸'\n",
      " '潑墨' '濃' '火車笛' '炊煙' '為' '為什麼' '煙雨' '牛仔' '牛奶' '牡丹' '狼狽' '猶如' '玩' '玩具' '現在'\n",
      " '理由' '瓶底' '留著' '當作' '盡量' '相信' '看不見' '真心' '眼帶' '眼淚' '眼睛' '睡得著' '知道' '硬幣'\n",
      " '碗底' '秘密' '稍嫌' '窗' '窗邊的' '窯燒裡' '笑' '笑意' '筆鋒' '等' '等不到' '答應' '簾外' '籬笆旁的'\n",
      " '約定' '紙飛機' '素胚' '結局' '結成' '給' '繞' '繡花針' '罰站' '美' '美女' '美麗' '而' '聊不完的'\n",
      " '聲音' '能不能' '腦海中' '臨摹' '自己' '自顧自' '至此' '與' '色白花青的' '芭蕉' '芭蕾' '英雄' '草皮'\n",
      " '萬不得已' '落地' '落款時' '蒲公英' '蜻蜓' '螞蟻' '蟬的' '被打撈起' '被私藏' '被隱去' '裊裊' '要' '要逃命前'\n",
      " '觀眾' '解藥' '記得' '記憶' '記憶裡' '認真' '說' '說了' '說好' '誰' '請你' '讓' '赤手空拳' '走' '走掉'\n",
      " '走筆' '跟' '跨不上去' '路過' '躍然於' '身體' '轉' '透過' '這裡' '這麼' '這麼近' '進行' '遇見' '還在'\n",
      " '還是' '還給' '那樣' '那江南小鎮' '那流星' '都' '都只穿' '都洗' '都累了' '都花了' '都跑到' '都還' '都靠'\n",
      " '酒吧' '釉色' '釋懷' '銅綠' '錦鯉' '錯過的' '長大的' '門環' '開始' '阻礙' '除非是' '隔江' '隨著' '隱藏'\n",
      " '雖然' '離開' '電影' '需要' '青花' '青花瓷' '韻味' '順便' '願望' '風景' '飄逸' '餵餵' '馬蹄' '騎毛驢'\n",
      " '驟雨']\n"
     ]
    }
   ],
   "source": [
    "# ===== Prepare Data =====\n",
    "cut_length = 0.5\n",
    "_n_split = 4\n",
    "FLAG_SAVE_MFCC = False    # set to True if want to store MFCC images\n",
    "\n",
    "audio_dir = './data/audio/'\n",
    "image_dir = './data/image/'\n",
    "label_dir = './data/label/'\n",
    "\n",
    "f_annotation = None\n",
    "if FLAG_SAVE_MFCC:\n",
    "    f_annotation = open('./data/total_annotation.csv', 'w')\n",
    "    print('file name, label', file=f_annotation)\n",
    "\n",
    "audio_list = os.listdir(audio_dir)\n",
    "print('Num of audio files:', len(audio_list))\n",
    "mfcc_list = []\n",
    "label_list = []\n",
    "state = 0\n",
    "\n",
    "# for all audio files\n",
    "print('===== Preprocess Data =====')\n",
    "for audio in audio_list:\n",
    "    # load audio\n",
    "    print('Processing', audio, '...')\n",
    "    y, sr = librosa.load(audio_dir + audio)\n",
    "\n",
    "    if state == 0:\n",
    "        state = 1\n",
    "    elif state == 1:\n",
    "        state = 2\n",
    "        y = np.concatenate((np.zeros(int(sr*0.05)), y)) # shift right to avoid overfitting\n",
    "    elif state == 2:\n",
    "        state = 3\n",
    "    elif state == 3:\n",
    "        state = 0\n",
    "        y = y[int(sr*0.05):]    # shift left to avoid overfitting\n",
    "\n",
    "    # get label file\n",
    "    song_name = audio[:-6]\n",
    "    f_label = open(label_dir + song_name + '.csv', 'r')\n",
    "\n",
    "    # get the first label\n",
    "    temp_label = f_label.readline().split(',')\n",
    "    temp_label = f_label.readline().split(',')\n",
    "    temp_label[0] = float(temp_label[0])\n",
    "    temp_label[1] = float(temp_label[1])\n",
    "\n",
    "    # cut to small pieces with length of cut_length seconds\n",
    "    for i in range(len(y) // int(cut_length * sr)):\n",
    "        y_cut = y[i * int(cut_length * sr): (i + 1) * int(cut_length * sr)]\n",
    "\n",
    "        # MFCC\n",
    "        mfcc = librosa.feature.mfcc(y=y_cut, sr=sr, n_mfcc=20)\n",
    "        mfcc_list.append(mfcc)\n",
    "        img_name = ''\n",
    "\n",
    "        # save as image if FLAG_SAVE_MFCC is True\n",
    "        if FLAG_SAVE_MFCC:\n",
    "            if i < 10:\n",
    "                img_name = audio[:-4] + '_0' + str(i) + '.png'\n",
    "            else:\n",
    "                img_name = audio[:-4] + '_' + str(i) + '.png'\n",
    "            # save as image\n",
    "            plt.figure(figsize=(5, 2), dpi=100)\n",
    "            librosa.display.specshow(mfcc)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(image_dir + img_name)\n",
    "            plt.close()\n",
    "\n",
    "        # record label\n",
    "        mid_time = (i + 0.5) * cut_length\n",
    "        while (temp_label[0] != '' and temp_label[1] < mid_time):   # if the clip is after the cur label, move to next label\n",
    "            temp_label = f_label.readline().split(',')\n",
    "            if temp_label[0] == '':\n",
    "                break\n",
    "            temp_label[0] = float(temp_label[0])\n",
    "            temp_label[1] = float(temp_label[1])\n",
    "        label = 'no lyrics'\n",
    "        if (temp_label[0] != '' and temp_label[0] < mid_time < temp_label[1]):  # some lyrics\n",
    "            label = temp_label[2]\n",
    "        label_list.append(label)\n",
    "\n",
    "        if FLAG_SAVE_MFCC:  \n",
    "            print(img_name, label, sep=', ', file=f_annotation)\n",
    "    \n",
    "    f_label.close()\n",
    "    \n",
    "if FLAG_SAVE_MFCC:\n",
    "    f_annotation.close()\n",
    "print('Done!')\n",
    "\n",
    "print('===== Prepare Dataset =====')\n",
    "# flatten the mfccs\n",
    "temp_mfccs_list = []\n",
    "for i in range(len(mfcc_list)):\n",
    "    temp_mfccs_list.append(mfcc_list[i].flatten())\n",
    "\n",
    "# prepare train and test dataset\n",
    "mfcc_array = np.array(temp_mfccs_list)\n",
    "print('mfcc_array:', mfcc_array.shape)\n",
    "label_array = np.array(label_list)\n",
    "print('label_array:', label_array.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(mfcc_array, label_array, test_size=0.2, random_state=23) # DON'T Modify Random_state!\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "\n",
    "# encode labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "label_array = le.fit_transform(label_array)\n",
    "label_classes = le.classes_\n",
    "print('number of classes:', len(label_classes))\n",
    "print(label_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training SVM Model =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=6000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.800997506234414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=6000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.8129675810473815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=6000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.8133000831255195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=6000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.7883272364482873\n",
      "===== Evaluate SVM Model =====\n",
      "Test accuracy: 0.7906899418121364\n",
      "Test precision_macro: 0.7901647749180237\n",
      "Test precision_micro: 0.7906899418121364\n",
      "Test precision_weighted: 0.8072738180877355\n",
      "Test recall_macro: 0.6795775760812488\n",
      "Test recall_micro: 0.7906899418121364\n",
      "Test recall_weighted: 0.7906899418121364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# ========== SVM ==========\n",
    "print('===== Training SVM Model =====')\n",
    "\n",
    "# # ========== Uncomment this block to train SVM model ==========\n",
    "# svm_model = SVC(kernel='linear', max_iter=6000)\n",
    "# # Perform K-fold cross-validation \n",
    "# kfold = KFold(n_splits=_n_split)\n",
    "# for train_index, val_index in kfold.split(X_train):\n",
    "#     X_train_kfold, X_val_kfold = X_train[train_index], X_train[val_index]\n",
    "#     y_train_kfold, y_val_kfold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "#     # train\n",
    "#     svm_model.fit(X_train_kfold, y_train_kfold)\n",
    "\n",
    "#     # see validation score\n",
    "#     pred_val = svm_model.predict(X_val_kfold)\n",
    "#     score = accuracy_score(y_val_kfold, pred_val)\n",
    "\n",
    "#     print(\"Validation score:\", score)\n",
    "# dump(svm_model, './model/svm_model.joblib')\n",
    "# # ========== end of training block ==========\n",
    "\n",
    "# ========== Uncomment this block to load trained SVM model ==========\n",
    "svm_model = load('./model/svm_model.joblib')\n",
    "# ========== end of loading block ==========\n",
    "\n",
    "# evaluate with the test set\n",
    "print('===== Evaluate SVM Model =====')\n",
    "pred_test = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred_test)\n",
    "precision_macro = precision_score(y_test, pred_test, average='macro')\n",
    "precision_micro = precision_score(y_test, pred_test, average='micro')\n",
    "precision_weighted = precision_score(y_test, pred_test, average='weighted')\n",
    "recall_macro = recall_score(y_test, pred_test, average='macro')\n",
    "recall_micro = recall_score(y_test, pred_test, average='micro')\n",
    "recall_weighted = recall_score(y_test, pred_test, average='weighted')\n",
    "print(\"Test accuracy:\", accuracy)\n",
    "print(\"Test precision_macro:\", precision_macro)\n",
    "print(\"Test precision_micro:\", precision_micro)\n",
    "print(\"Test precision_weighted:\", precision_weighted)\n",
    "print(\"Test recall_macro:\", recall_macro)\n",
    "print(\"Test recall_micro:\", recall_micro)\n",
    "print(\"Test recall_weighted:\", recall_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========== Decision Tree ==========\n",
    "# print('===== Training Decision Tree Model =====')\n",
    "\n",
    "# # ========== Uncomment this block to train Decision Tree model ==========\n",
    "# decision_tree_model = DecisionTreeClassifier()\n",
    "# # Perform K-fold cross-validation \n",
    "# kfold = KFold(n_splits=_n_split)\n",
    "# for train_index, val_index in kfold.split(X_train):\n",
    "#     X_train_kfold, X_val_kfold = X_train[train_index], X_train[val_index]\n",
    "#     y_train_kfold, y_val_kfold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "#     # train\n",
    "#     decision_tree_model.fit(X_train_kfold, y_train_kfold)\n",
    "\n",
    "#     # see validation score\n",
    "#     pred_val = decision_tree_model.predict(X_val_kfold)\n",
    "#     score = accuracy_score(y_val_kfold, pred_val)\n",
    "\n",
    "#     print(\"Validation score:\", score)\n",
    "# dump(decision_tree_model, './model/decision_tree_model.joblib')\n",
    "# # ========== end of training block ==========\n",
    "\n",
    "# # # ========== Uncomment this block to load trained Decision Tree model ==========\n",
    "# # decision_tree_model = load('./model/decision_tree_model.joblib')\n",
    "# # # ========== end of loading block ==========\n",
    "\n",
    "# # evaluate with the test set\n",
    "# print('===== Evaluate Decision Tree Model =====')\n",
    "# pred_test = decision_tree_model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, pred_test)\n",
    "# precision_macro = precision_score(y_test, pred_test, average='macro')\n",
    "# precision_micro = precision_score(y_test, pred_test, average='micro')\n",
    "# precision_weighted = precision_score(y_test, pred_test, average='weighted')\n",
    "# recall_macro = recall_score(y_test, pred_test, average='macro')\n",
    "# recall_micro = recall_score(y_test, pred_test, average='micro')\n",
    "# recall_weighted = recall_score(y_test, pred_test, average='weighted')\n",
    "# print(\"Test accuracy:\", accuracy)\n",
    "# print(\"Test precision_macro:\", precision_macro)\n",
    "# print(\"Test precision_micro:\", precision_micro)\n",
    "# print(\"Test precision_weighted:\", precision_weighted)\n",
    "# print(\"Test recall_macro:\", recall_macro)\n",
    "# print(\"Test recall_micro:\", recall_micro)\n",
    "# print(\"Test recall_weighted:\", recall_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training MLP Model =====\n",
      "Validation score: 0.856691604322527\n",
      "Validation score: 0.8365752285951787\n",
      "Validation score: 0.8515378221113882\n",
      "Validation score: 0.820917858330562\n",
      "===== Evaluate MLP Model =====\n",
      "Test accuracy: 0.8327514546965918\n",
      "Test precision_macro: 0.778471248768338\n",
      "Test precision_micro: 0.8327514546965918\n",
      "Test precision_weighted: 0.8529033755917654\n",
      "Test recall_macro: 0.7554771865529839\n",
      "Test recall_micro: 0.8327514546965918\n",
      "Test recall_weighted: 0.8327514546965918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# ========== MLP ==========\n",
    "print('===== Training MLP Model =====')\n",
    "\n",
    "# # ========== Uncomment this block to train MLP model ==========\n",
    "# MLP_model = MLPClassifier(hidden_layer_sizes=(1024, 128), max_iter=800)\n",
    "# # Perform K-fold cross-validation \n",
    "# kfold = KFold(n_splits=_n_split)\n",
    "# for train_index, val_index in kfold.split(X_train):\n",
    "#     X_train_kfold, X_val_kfold = X_train[train_index], X_train[val_index]\n",
    "#     y_train_kfold, y_val_kfold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "#     # train\n",
    "#     MLP_model.fit(X_train_kfold, y_train_kfold)\n",
    "\n",
    "#     # see validation score\n",
    "#     pred_val = MLP_model.predict(X_val_kfold)\n",
    "#     score = accuracy_score(y_val_kfold, pred_val)\n",
    "\n",
    "#     print(\"Validation score:\", score)\n",
    "# dump(MLP_model, './model/MLP_model.joblib')\n",
    "# # ========== end of training block ==========\n",
    "\n",
    "# ========== Uncomment this block to load trained MLP model ==========\n",
    "MLP_model = load('./model/MLP_model.joblib')\n",
    "# ========== end of loading block ==========\n",
    "\n",
    "# evaluate with the test set\n",
    "print('===== Evaluate MLP Model =====')\n",
    "pred_test = MLP_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred_test)\n",
    "precision_macro = precision_score(y_test, pred_test, average='macro')\n",
    "precision_micro = precision_score(y_test, pred_test, average='micro')\n",
    "precision_weighted = precision_score(y_test, pred_test, average='weighted')\n",
    "recall_macro = recall_score(y_test, pred_test, average='macro')\n",
    "recall_micro = recall_score(y_test, pred_test, average='micro')\n",
    "recall_weighted = recall_score(y_test, pred_test, average='weighted')\n",
    "print(\"Test accuracy:\", accuracy)\n",
    "print(\"Test precision_macro:\", precision_macro)\n",
    "print(\"Test precision_micro:\", precision_micro)\n",
    "print(\"Test precision_weighted:\", precision_weighted)\n",
    "print(\"Test recall_macro:\", recall_macro)\n",
    "print(\"Test recall_micro:\", recall_micro)\n",
    "print(\"Test recall_weighted:\", recall_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test file: 最長的電影00.wav\n",
      "test file: 蒲公英的約定00.wav\n",
      "test file: 不用麻煩了.wav\n",
      "test file: 再給我兩分鐘.wav\n",
      "test file: 決定命運的硬幣.wav\n",
      "test file: 校長都看我幾.wav\n",
      "test file: 彩虹00.wav\n",
      "test file: 青花瓷00.wav\n",
      "test file: 牛仔很忙00.wav\n"
     ]
    }
   ],
   "source": [
    "# ===== DEMO with the original song clips =====\n",
    "demo_dir = './demo/'\n",
    "test_files = os.listdir(demo_dir)\n",
    "\n",
    "for test_file in test_files:\n",
    "    if test_file[-4:] != '.wav':\n",
    "        continue\n",
    "    \n",
    "    print('test file:', test_file)\n",
    "\n",
    "    svm_predict_list = []\n",
    "    decision_tree_predict_list = []\n",
    "    MLP_predict_list = []\n",
    "\n",
    "    # load the test file\n",
    "    y, sr = librosa.load(demo_dir + test_file)\n",
    "\n",
    "    # cut to small pieces with length of cut_length seconds\n",
    "    for i in range(len(y) // int(cut_length * sr)):\n",
    "        y_cut = y[i * int(cut_length * sr): (i + 1) * int(cut_length * sr)]\n",
    "        mfcc = librosa.feature.mfcc(y=y_cut, sr=sr, n_mfcc=20)\n",
    "        mfcc_reshape = mfcc.reshape(1, -1)\n",
    "        # SVM\n",
    "        svm_predict = svm_model.predict(mfcc_reshape)\n",
    "        svm_predict_list.append( (i*cut_length, (i+1)*cut_length, svm_predict[0]) )\n",
    "        # # Decision Tree\n",
    "        # decision_tree_predict = decision_tree_model.predict(mfcc_reshape)\n",
    "        # decision_tree_predict_list.append( (i*cut_length, (i+1)*cut_length, decision_tree_predict[0]) )\n",
    "        # MLP\n",
    "        MLP_predict = MLP_model.predict(mfcc_reshape)\n",
    "        MLP_predict_list.append( (i*cut_length, (i+1)*cut_length, MLP_predict[0]) )\n",
    "\n",
    "    # SVM\n",
    "    f_svm_result = open(demo_dir + 'output/' + test_file[:-4] + '_svm_no_vote.txt', 'w')\n",
    "    print('start, end, label', file=f_svm_result)\n",
    "    start, end, label = svm_predict_list.pop(0)\n",
    "    while len(svm_predict_list) > 0:\n",
    "        if label == svm_predict_list[0][2]:\n",
    "            end = svm_predict_list[0][1]\n",
    "            svm_predict_list.pop(0)\n",
    "        else:\n",
    "            print(str(round(start, 2)) + ', ' + str(round(end, 2)) + ', ' + str(label), file=f_svm_result)\n",
    "            start, end, label = svm_predict_list.pop(0)\n",
    "    print(str(round(start, 2)) + ', ' + str(round(end, 2)) + ', ' + str(label), file=f_svm_result)\n",
    "    f_svm_result.close()\n",
    "\n",
    "    # # Decision Tree\n",
    "    # f_decision_tree_result = open(demo_dir + 'output/' + test_file[:-4] + '_decision_tree_no_vote.txt', 'w')\n",
    "    # print('start, end, label', file=f_decision_tree_result)\n",
    "    # start, end, label = decision_tree_predict_list.pop(0)\n",
    "    # while len(decision_tree_predict_list) > 0:\n",
    "    #     if label == decision_tree_predict_list[0][2]:\n",
    "    #         end = decision_tree_predict_list[0][1]\n",
    "    #         decision_tree_predict_list.pop(0)\n",
    "    #     else:\n",
    "    #         print(str(round(start, 2)) + ', ' + str(round(end, 2)) + ', ' + str(label), file=f_decision_tree_result)\n",
    "    #         start, end, label = decision_tree_predict_list.pop(0)\n",
    "    # print(str(round(start, 2)) + ', ' + str(round(end, 2)) + ', ' + str(label), file=f_decision_tree_result)\n",
    "    # f_decision_tree_result.close()\n",
    "\n",
    "    # MLP\n",
    "    f_MLP_result = open(demo_dir + 'output/' + test_file[:-4] + '_MLP_no_vote.txt', 'w')\n",
    "    print('start, end, label', file=f_MLP_result)\n",
    "    start, end, label = MLP_predict_list.pop(0)\n",
    "    while len(MLP_predict_list) > 0:\n",
    "        if label == MLP_predict_list[0][2]:\n",
    "            end = MLP_predict_list[0][1]\n",
    "            MLP_predict_list.pop(0)\n",
    "        else:\n",
    "            print(str(round(start, 2)) + ', ' + str(round(end, 2)) + ', ' + str(label), file=f_MLP_result)\n",
    "            start, end, label = MLP_predict_list.pop(0)\n",
    "    print(str(round(start, 2)) + ', ' + str(round(end, 2)) + ', ' + str(label), file=f_MLP_result)\n",
    "    f_MLP_result.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== prepare dataset and dataloader for ResNet50 =====\n",
    "# class CustomImageDataset(Dataset):\n",
    "#     def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "#         self.img_labels = pd.read_csv(annotations_file)\n",
    "#         self.img_dir = img_dir\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_labels)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "#         image = read_image(img_path)[0:3, :, :]\n",
    "#         label = self.img_labels.iloc[idx, 1]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         if self.target_transform:\n",
    "#             label = self.target_transform(label)\n",
    "#         return image, label\n",
    "    \n",
    "# dataset = CustomImageDataset(annotations_file='./data/total_annotation.csv', img_dir='./data/image/')\n",
    "# # split to train and test\n",
    "# print(len(dataset))\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "# print('Num of train data:', len(train_dataset))\n",
    "# print('Num of test data:', len(test_dataset))\n",
    "# # dataloader\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# # # ===== Display one image and label =====\n",
    "# # train_features, train_labels = next(iter(train_dataloader))\n",
    "# # img = train_features[0].permute(1, 2, 0)\n",
    "# # label = train_labels[0]\n",
    "# # plt.imshow(img)\n",
    "# # plt.axis('off')\n",
    "# # plt.show()\n",
    "# # print(f\"Label: {label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
